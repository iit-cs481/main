{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification:\n",
    "\n",
    "The process of categorizing text into pre-defined groups/classes\n",
    "<img src=\"classification.png\" width=\"600\" align=\"left\">\n",
    "\n",
    "<br><br><br><br><br><br><br><br>\n",
    "Organize unstructured text to extract value and get insights into:\n",
    "    - social media messages\n",
    "    - emails\n",
    "    - online conversations (chat-bots)\n",
    "    - websites\n",
    "    \n",
    "    \n",
    "- **Applications** of automatic text classification:\n",
    "    - Sentiment Analysis: understand the view / attitute / feeling / emotion toward a situation or event. We do text classification to analyze if a given text is talking positively or negatively about a given subject (e.g. pos/neg movie review). \n",
    "\n",
    "    - Topic Labeling: identify the theme or topic in the text (e.g. analyze the topics of news articles: entertainment, business, politics).\n",
    "\n",
    "    - Spam Detection: detect whether an email is spam or not.\n",
    "\n",
    "\n",
    "\n",
    "- **Approaches**:\n",
    "    - manual\n",
    "        - human annotator read and label the text\n",
    "        - platform: AMT\n",
    "        - pros: high quality\n",
    "        - cons: time consuming and expensive  \n",
    "        \n",
    "    - automatic        \n",
    "        - rule-based\n",
    "            - pre-define a set of linguistic rules\n",
    "            - instruct the system to use semantically relevant elements of a text to identify relevant categories based on its content\n",
    "            - E.g., classify news article into sports and politics\n",
    "                - sports-related keywords: football, basketball, LeBron James\n",
    "                - politics-related keywords: government, Washington, Obama, Donald Trump, Hillary Clinton, etc.\n",
    "            - cons: difficult and expensive to maintain\n",
    "\n",
    "        - **machine learning-based**\n",
    "            - train a classifier based on pre-labeled training data\n",
    "            - apply the classifier to make predictions on new data\n",
    "            - pros: fast, effective, accurate\n",
    "            - cons: need pre-labeled training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary sentiment classification for IMDb movie reviews:\n",
    "\n",
    "- IMDb: Internet Movie Database, is an online database of information related to films, television programs, and so on.\n",
    "- Task: train a binary classification model to predict whether a movie review is positive or negative.\n",
    "\n",
    "<img src=\"IMDb_review.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "\n",
    "import seaborn as sns # visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and explore the data\n",
    "The data is available at this source, and you can learn more about how and why this dataset is created from this paper. <br>\n",
    "Data source: https://ai.stanford.edu/~amaas/data/sentiment/ <br>\n",
    "Paper: [Learning Word Vectors for Sentiment Analysis](https://ai.stanford.edu/~ang/papers/acl11-WordVectorsSentimentAnalysis.pdf) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((50000, 2), None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we first download the data, and then use pandas dataframe to load the data from file\n",
    "df_data = pd.read_csv('IMDB Dataset.csv')\n",
    "df_data.shape, display(df_data.head())\n",
    "# we can see there are 50,000 reviews, each review is either positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('negative',\n",
       " 'Phil the Alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines.<br /><br />At first it was very odd and pretty funny but as the movie progressed I didn\\'t find the jokes or oddness funny anymore.<br /><br />Its a low budget film (thats never a problem in itself), there were some pretty interesting characters, but eventually I just lost interest.<br /><br />I imagine this film would appeal to a stoner who is currently partaking.<br /><br />For something similar but better try \"Brother from another planet\"')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is an example of negative review\n",
    "df_data.iloc[10].sentiment, df_data.iloc[10].review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then explore more about this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check empty cells\n",
    "df_data.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicate samples\n",
    "df_data = df_data.drop_duplicates(keep=\"first\")\n",
    "df_data.shape\n",
    "# compare with the original data 50,000, we removed about 500 duplicate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    24884\n",
       "negative    24698\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if pos and neg sentiments are balanced\n",
    "df_data.sentiment.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is equally distributed, which is great for building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets check the length of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    49582.000000\n",
       "mean      1310.568230\n",
       "std        990.762238\n",
       "min         32.000000\n",
       "25%        699.000000\n",
       "50%        971.000000\n",
       "75%       1592.000000\n",
       "max      13704.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['length'] = df_data['review'].apply(len) # number of characters\n",
    "df_data['length'].describe() # info()\n",
    "# the describe function shows the mean, std, min, max of length of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  length\n",
       "0  One of the other reviewers has mentioned that ...  positive    1761\n",
       "1  A wonderful little production. <br /><br />The...  positive     998\n",
       "2  I thought this was a wonderful way to spend ti...  positive     926\n",
       "3  Basically there's a family where a little boy ...  negative     748\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive    1317"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have a new column 'length' added to the dataframe\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of the length of positive and negative reviews\n",
    "# x: length of reviews; y: number of reviews fall into each interval\n",
    "df_data.hist(column='length', by='sentiment',bins=30, figsize=(12,4),rwidth=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above distribution, we can say that there is no clear difference between postive and negative reviews based on the length of the review.\n",
    "\n",
    "After the exploration, we now have a basic understanding of the dataset.\n",
    "Lets go ahead to clean the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing \n",
    "There are many approaches for text preprocessing, such as:\n",
    "- lowercasing\n",
    "- data cleaning \n",
    "    > remove special characters, emails, urls <br>\n",
    "    > remove stopwords <br>\n",
    "    > remove punctuations <br>\n",
    "        \n",
    "- normalization\n",
    "    > stemming \n",
    "        - chops off the ends of words to transform words into their root forms (e.g., connected->connect)\n",
    "        - PorterStemmer, SnowballStemmer\n",
    "    > lemmatization\n",
    "        - map a word to its root form (dictionary, rule-based) based on the context, POS, intended meaning\n",
    "        - WordNetLemmatizer\n",
    "        - transforming a text into a standard form (abbreviations, misspellings, out-of-vocabulary words; e.g., gooood->good)\n",
    "    > De-contract\n",
    "        - expand the contracted words into normal words (I'm -> I am)\n",
    "\n",
    "The specific steps to apply depends on your task. <br>\n",
    "For our task of analyzing IMDb movie reviews data, we mainly focus on **data cleaning**, such as removing:\n",
    "\n",
    "> HTML tags <br>\n",
    "> special / non-alphabetic characters <br>\n",
    "> url <br>\n",
    "> emails <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example of the review, we can see that ...\n",
    "df_data.review[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49582/49582 [00:25<00:00, 1949.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1761</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>998</td>\n",
       "      <td>A wonderful little production  The filming tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>926</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>748</td>\n",
       "      <td>Basically there is a family where a little boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1317</td>\n",
       "      <td>Petter Mattei is  Love in the Time of Money  i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  length  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive    1761   \n",
       "1  A wonderful little production. <br /><br />The...  positive     998   \n",
       "2  I thought this was a wonderful way to spend ti...  positive     926   \n",
       "3  Basically there's a family where a little boy ...  negative     748   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive    1317   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  One of the other reviewers has mentioned that ...  \n",
       "1  A wonderful little production  The filming tec...  \n",
       "2  I thought this was a wonderful way to spend ti...  \n",
       "3  Basically there is a family where a little boy...  \n",
       "4  Petter Mattei is  Love in the Time of Money  i...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def decontracted(phrase):\n",
    "    \"\"\"\n",
    "    We first define a function to expand the contracted phrase into normal words\n",
    "    \"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase) # prime \n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "def clean_text(df):\n",
    "    \"\"\"\n",
    "    Clean the review texts\n",
    "    \"\"\"\n",
    "    cleaned_review = []\n",
    "\n",
    "    for review_text in tqdm(df['review']):\n",
    "        \n",
    "        # expand the contracted words\n",
    "        review_text = decontracted(review_text)\n",
    "        \n",
    "        #remove html tags\n",
    "        review_text = BeautifulSoup(review_text, 'lxml').get_text().strip() # re.sub(r'<.*?>', '', text)\n",
    "        \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "        #remove url \n",
    "        review_text = re.sub(r'https?://\\S+|www\\.\\S+', '', review_text)\n",
    "        \n",
    "        #Removing punctutation, string.punctuation in python consists of !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`\n",
    "        review_text = review_text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # ''.join([char for char in movie_text_data if char not in string.punctuation])\n",
    "        \n",
    "        # remove emails\n",
    "        review_text = re.sub(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", '', review_text)\n",
    "    \n",
    "        cleaned_review.append(review_text)\n",
    "\n",
    "    return cleaned_review\n",
    "\n",
    "df_data['cleaned_review'] = clean_text(df_data)\n",
    "# df_data['cleaned_review'] = df_data.apply(clean_text)\n",
    "# df_data = df_data.drop(columns=['review'])\n",
    "\n",
    "df_data.head()\n",
    "# After the cleaning process, we get the cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!! \n",
      "\n",
      "If you like original gut wrenching laughter you will like this movie  If you are young or old then you will love this movie  hell even my mom liked it Great Camp   \n"
     ]
    }
   ],
   "source": [
    "# example of a review before and after cleaning, we can see that the punctuations and html tags are removed.\n",
    "\n",
    "print(df_data['review'][9],'\\n')\n",
    "\n",
    "print(df_data['cleaned_review'][9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving forward, we convert the sentiments to binary labels, the corresponding label for postive sentiment is 1 and 0 for negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production  The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there is a family where a little boy...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei is  Love in the Time of Money  i...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_review sentiment  label\n",
       "0  One of the other reviewers has mentioned that ...  positive      1\n",
       "1  A wonderful little production  The filming tec...  positive      1\n",
       "2  I thought this was a wonderful way to spend ti...  positive      1\n",
       "3  Basically there is a family where a little boy...  negative      0\n",
       "4  Petter Mattei is  Love in the Time of Money  i...  positive      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['label'] = df_data['sentiment'].map({'positive':1,'negative':0})\n",
    "df_data.head()[['cleaned_review','sentiment','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Feature engineering for text is the process of transforming raw texts into vector representations that the machine learning models can understand.\n",
    "\n",
    "**Pipeline** for training a text classifier\n",
    "\n",
    "<img src=\"training.png\" width=\"800\" align=\"center\">\n",
    "\n",
    "\n",
    "**Feature engineering techniques**:\n",
    "- Units\n",
    "    > words <br>\n",
    "    > phrases <br>\n",
    "    > POS tag <br>\n",
    "- doc:\n",
    "    > https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "- CountVectorizer \n",
    "    > represent document as a vector of word counts\n",
    "- TfidfVectorizer \n",
    "    > term-frequency * inverse document-frequency\n",
    "    > reduce very frequent terms (e.g., 'a', 'the', 'is')\n",
    "- Embedding \n",
    "    > represent words into high-dimensional vectors\n",
    "    > word2vec, BERT, GPT, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools and packages for ML:\n",
    "- **scikit-learn**: https://scikit-learn.org/stable/\n",
    "- a free software machine learning library for Python \n",
    "- algorithms for:\n",
    "    - feature engineering\n",
    "    - classification\n",
    "    - regression \n",
    "    - clustering\n",
    "    - evaluation metric (e.g., precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "- Convert a collection of text documents to a matrix of token counts\n",
    "- doc: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "         'This is the first document.',\n",
    "         'This document is the second document.',\n",
    "         'And this is the third one.',\n",
    "         'Is this the first document?',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1]\n",
      " [2 0 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus) # Learn the vocabulary dictionary and return document-term matrix\n",
    "print(X.toarray())\n",
    "# columns represent features\n",
    "# each row corresponds to a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(X))\n",
    "# print(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()) # Array mapping from feature integer indices to feature name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 8,\n",
       " 'is': 3,\n",
       " 'the': 6,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 5,\n",
       " 'and': 0,\n",
       " 'third': 7,\n",
       " 'one': 4}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_ # A mapping from terms to feature indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ngrams as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
      " [0 0 1 0 1 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X2 = vectorizer2.fit_transform(corpus)\n",
    "\n",
    "print(X2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and this', 'document is', 'first document', 'is the', 'is this', 'second document', 'the first', 'the second', 'the third', 'third one', 'this document', 'this is', 'this the']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer2.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Other important parameters:\n",
    "    > min_df: ignore terms that have a document frequency lower than the given threshold <br>\n",
    "    > max_df: ignore terms that have a document frequency lower than the given threshold(e.g., corpus-specific stop words) <br>\n",
    "    > lowercase <br>\n",
    "    > max_features <br>\n",
    "    > vocabulary <br>\n",
    "    > binary <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer\n",
    "- term-frequency * inverse document-frequency\n",
    "\n",
    "- term-frequency: the number of times a term occurs in a given document\n",
    "\n",
    "- Inverse document frequency:\n",
    "\n",
    "<img src=\"idf.png\" width=\"300\" align=\"center\">\n",
    "\n",
    "\n",
    "- Euclidean norm:\n",
    "\n",
    "<img src=\"euclidean_norm.png\" width=\"500\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 9)\n",
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      "  0.28108867 0.         0.28108867]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, we will use the **scikit-learn** implementation of [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to convert the movie reviews into a 2-d matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape :  (49582, 47192)\n",
      "y.shape :  (49582,)\n"
     ]
    }
   ],
   "source": [
    "# print(stopwords.words('english'))\n",
    "#Exluding NO, NOR, NOT from the stop words as they play keyrole\n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "\n",
    "\n",
    "# In the CountVectorizer, we ask it to lowercase the text, use a self-defined stopwords list to remove stopwords\n",
    "# Will talk about how to tune these parameters later.\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=stopwords, max_df=0.9, min_df=3, ngram_range=(1,1))\n",
    "\n",
    "# convert the cleaned reviews to vectors\n",
    "X = vectorizer.fit_transform(df_data.cleaned_review)\n",
    "y = df_data.label.values\n",
    "\n",
    "print(\"X.shape : \",X.shape)\n",
    "print(\"y.shape : \",y.shape)\n",
    "\n",
    "# X is the 2-d matrix of vector representation of the cleaned reviews\n",
    "# y is the array of sentiment labels\n",
    "# accoring to the shape of X, we can tell the number of samples, the number of features (size of vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split\n",
    "Split the data into training and testing by 80:20 ratio after shuffling the data, assign a random state for reproducible output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes : X : (39665, 47192), y : (39665,)\n",
      "Test shapes : X : (9917, 47192), y : (9917,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle=True,random_state=42) # shuffle: re-arrange, randomize\n",
    "print(\"Train shapes : X : {}, y : {}\".format(X_train.shape,y_train.shape))\n",
    "print(\"Test shapes : X : {}, y : {}\".format(X_test.shape,y_test.shape))\n",
    "# For example, after train test split, we get 39665 samples in the training set and 9917 in the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "After we do text preprocessing, feature engineering, and train test split, the next step is model training, we need to decide which model to use. For example, there are:\n",
    "\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Decision Tree\n",
    "- K-Nearest Neighbors\n",
    "- Support Vector Machines\n",
    "- (Deep) Neural Networks\n",
    "- ... many many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"training_prediction.png\" width=\"800\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "In this task, we will use **Logistic regression**, which is one of the most popular and interpretable machine learning algorithm for binary classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**: linear combination of independent variables,\n",
    "$$\n",
    "    t = \\sum_{i} {\\beta_i*x_i}\n",
    "$$\n",
    "\n",
    "**Logistic Regression**: regression with output constrained between 0 and 1 with a sigmoid logistic function, as we see here, combine the linear regression with a logistic function, we get the logistic regression function:\n",
    "  \n",
    "$$ \n",
    "    \\hat{y} = \\frac{1}{1 + \\exp (- t)}  = \\frac{1}{1 + \\exp (-\\sum_i\\beta_i x_i)} \n",
    "$$\n",
    "\n",
    "- $x_i$ is value of feature $i$ in an instance (count of a word)<br>\n",
    "- $\\beta_i$ is the real-valued model parameter associated with feature $i$ <br>\n",
    "  - E.g., high $\\beta_i$ means feature $i$ is predictive of positive class ($y=1$) <br>\n",
    "- $\\hat{y}$ is the probability of being positive, $y$ is the actual label <br>\n",
    "    - If $\\hat{y} > .5$, classify as positive, $y = 1$ <br>\n",
    "\n",
    "\n",
    "<img src=\"Logistic_curve.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a logistic regression classifier on the training data use default settings\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# make prediction on testing data\n",
    "y_pred_test = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
