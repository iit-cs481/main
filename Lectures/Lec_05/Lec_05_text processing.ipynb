{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./outline.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"/data/3/zwang/nltk_data\") # setting environment variable to your path\n",
    "\n",
    "# show the plot in file\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currency exchange example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./currency_exchange.png\" width=\"1000\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing with unicode\n",
    "- Computers just deal with numbers\n",
    "    - letters and characters are assigned to a number\n",
    "    \n",
    "- Texts in different languages has different character encoding systems:\n",
    "    - English, ASCII\n",
    "    - Europe, Latin (e.g., \"ø\", \"ő\", \"ñ\", \"ň\")\n",
    "    - India, Hindi, ISCII (Indian Script Code for Information Interchange)\n",
    "    - China, GB2321\n",
    "    - Korea, Window 949\n",
    "    \n",
    "- Earlier character encodings were limited:\n",
    "    - not cover characters for all the world’s languages\n",
    "    - no single encoding covered all the letters, punctuation, and technical symbols in common use.  \n",
    "\n",
    "- Conflicted with each another:  \n",
    "    - two encodings could use the same number for two different characters\n",
    "    - use different numbers for the same character\n",
    "\n",
    "- Challenge to support pictographic languages:\n",
    "    - Japanese (e.g., こんばんは)\n",
    "    - Chinese (e.g., 自然语言处理)\n",
    "\n",
    "- Passing data between computers that have different character encoding systems:\n",
    "    - corruption\n",
    "    - conflict\n",
    "    - errors\n",
    "\n",
    "- Any ideas for dealing with this issue?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode characters \n",
    "- Unicode Standard:\n",
    "    - the universal character encoding standard used for representation of text for computer processing\n",
    "\n",
    "- A global standard to support all the world’s languages\n",
    "    - An encoding large enough to support the writing systems of all the world’s languages\n",
    "    - Provides a standardized system of character codes\n",
    "    - https://unicode.org/standard/principles.html\n",
    "    - https://www.unicode.org/charts/\n",
    "    \n",
    "    \n",
    "- A unique code for:\n",
    "    - every character, in every language, in every program, on every platform\n",
    "    - enables computers to support virtually every language\n",
    "    - codes for more than 135,000 characters: \n",
    "        - the world's alphabets\n",
    "        - writing systems\n",
    "        - symbols\n",
    "        \n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASCII \n",
    "- American Standard Code for Information Interchange\n",
    "    - first edition published in 1963\n",
    "    \n",
    "\n",
    "- ASCII character table:\n",
    "    - ASCII table: http://www.asciitable.com/\n",
    "    - encodes 128 characters into **seven-bit** integers\n",
    "    - 95 printable characters:\n",
    "        - digits 0 to 9, \n",
    "        - lowercase letters a to z, \n",
    "        - uppercase letters A to Z, \n",
    "        - and punctuation symbols. \n",
    "    - 33 non-printing control codes\n",
    "    - E.g., lowercase i: \n",
    "        - binary 1101001 = hexadecimal 69 = decimal 105\n",
    "        - hexadecimal\n",
    "        - octal\n",
    "    \n",
    "- Usecase: CV in ASCII format:\n",
    "    - 'plain' text with no formatting such as tabs, bold or underscoring \n",
    "    - Notepad++ (ANSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ASCII.png\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unicode in Python\n",
    "- **code point**: each character is assigned a number\n",
    "    - \\uXXXX, 4-digit hexadecimal\n",
    "    - single byte per code point (e.g., ASCII and Latin-2), support a small subset of Unicode, enough for a single language\n",
    "    - multiple bytes per code point (e.g., UTF-8) and can represent the full range of Unicode characters\n",
    "    - In Python 3, source code is encoded using UTF-8 by default\n",
    "    \n",
    "\n",
    "- **decoding**: \n",
    "    - file/terminal --> program\n",
    "    - bytes --> Unicode\n",
    "- **encoding**: \n",
    "    - program --> file/terminal\n",
    "    - Unicode --> bytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./encode_decode.png\" width=\"500\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting encoded text from files\n",
    "- a small text file and we know how it is encoded \n",
    "- For example, polish-lat2.txt, Polish text encoded as Latin-2, also known as ISO-8859-2. \n",
    "    - Polish Wikipedia: http://pl.wikipedia.org/wiki/Biblioteka_Pruska"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileSystemPathPointer('/data/3/zwang/nltk_data/corpora/unicode_samples/polish-lat2.txt')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# locate the file path\n",
    "path = nltk.data.find('corpora/unicode_samples/polish-lat2.txt') \n",
    "path\n",
    "# this is the location in my computer and you might have a different path in your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruska Biblioteka Państwowa. Jej dawne zbiory znane pod nazwą\n",
      "\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez\n",
      "Niemców pod koniec II wojny światowej na Dolny Śląsk, zostały\n",
      "odnalezione po 1945 r. na terytorium Polski. Trafiły do Biblioteki\n",
      "Jagiellońskiej w Krakowie, obejmują ponad 500 tys. zabytkowych\n",
      "archiwaliów, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.\n"
     ]
    }
   ],
   "source": [
    "# read encoded data into Unicode strings and write out Unicode strings in encoded form\n",
    "# parameter \"encoding\" to specify the encoding of the file being read or written\n",
    "f = open(path, encoding='latin2') # what if a wrong encoding? GB2312\n",
    "for line in f:\n",
    "    line = line.strip() # remove the leading and the trailing characters (e.g., space, \\n)\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the underlying numerical values (or \"codepoints\") of the characters:\n",
    "    - convert all non-ASCII characters into their two-digit \\xXX and four-digit \\uXXXX representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Pruska Biblioteka Pa\\\\u0144stwowa. Jej dawne zbiory znane pod nazw\\\\u0105'\n",
      "b'\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez'\n",
      "b'Niemc\\\\xf3w pod koniec II wojny \\\\u015bwiatowej na Dolny \\\\u015al\\\\u0105sk, zosta\\\\u0142y'\n",
      "b'odnalezione po 1945 r. na terytorium Polski. Trafi\\\\u0142y do Biblioteki'\n",
      "b'Jagiello\\\\u0144skiej w Krakowie, obejmuj\\\\u0105 ponad 500 tys. zabytkowych'\n",
      "b'archiwali\\\\xf3w, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.'\n"
     ]
    }
   ],
   "source": [
    "f = open(path, encoding='latin2')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    print(line.encode('unicode_escape'))\n",
    "    \n",
    "# \\u0144: a Unicode escape string preceded by the \\u escape string, display on the screen as ń\n",
    "# \\xf3: display as ó, and is within the 128-255 range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Arbitrary Unicode characters can be included using the \\uXXXX escape sequence \n",
    "    - X is hexadecimal digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the number representing the unicode code of a specified character\n",
    "ord('ń')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ń\n"
     ]
    }
   ],
   "source": [
    "u_char = '\\u0144' # unicode 4 + 16*4 + 16*16*1 = 324\n",
    "print(u_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "㺬\n"
     ]
    }
   ],
   "source": [
    "u_char = '\\u3eac' # unicode\n",
    "print(u_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ó'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = '\\u00f3'\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xe3\\xba\\xac'\n"
     ]
    }
   ],
   "source": [
    "# check how this character is represented as a sequence of bytes inside a text file\n",
    "print(u_char.encode('utf8')) \n",
    "# b' ': bytes literals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- properties of Unicode characters\n",
    "    - unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Niemców pod koniec II wojny światowej na Dolny Śląsk, zostały\n",
      "\n",
      "b'Niemc\\\\xf3w pod koniec II wojny \\\\u015bwiatowej na Dolny \\\\u015al\\\\u0105sk, zosta\\\\u0142y\\\\n'\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "lines = open(path, encoding='latin2').readlines()\n",
    "\n",
    "# select characters in the third line of the Polish text\n",
    "line = lines[2] # texts in the third line\n",
    "\n",
    "print(line)\n",
    "print(line.encode('unicode_escape')) # unicode representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check characters outside the ASCII range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ó b'\\xc3\\xb3' U+00f3 LATIN SMALL LETTER O WITH ACUTE\n",
      "ś b'\\xc5\\x9b' U+015b LATIN SMALL LETTER S WITH ACUTE\n",
      "Ś b'\\xc5\\x9a' U+015a LATIN CAPITAL LETTER S WITH ACUTE\n",
      "ą b'\\xc4\\x85' U+0105 LATIN SMALL LETTER A WITH OGONEK\n",
      "ł b'\\xc5\\x82' U+0142 LATIN SMALL LETTER L WITH STROKE\n"
     ]
    }
   ],
   "source": [
    "for c in line: # iterate over character\n",
    "    if ord(c) > 127: # text outside the ASCII range\n",
    "        print('{} {} U+{:04x} {}'.format(c, c.encode('utf8'), ord(c), unicodedata.name(c))) \n",
    "        # try to replace c.encode('utf8') with c\n",
    "\n",
    "# the character, utf8 byte sequence, unicode code point, unicode name (description for the character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Text from different sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online resources\n",
    "- Kaggle:\n",
    "    - https://www.kaggle.com/datasets\n",
    "- Github:\n",
    "    - https://github.com/niderhoff/nlp-datasets\n",
    "    - topics: nlp-dataset\n",
    "- Yelp:\n",
    "    - https://www.yelp.com/dataset\n",
    "- Airbnb\n",
    "    - http://insideairbnb.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing web text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./processing_pipeline.png\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online electronic books\n",
    "- Project Gutenberg\n",
    "- free online ebooks: http://www.gutenberg.org/catalog/\n",
    "- over 50 languages, 90% in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(str, 1176967)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "# open url and read it into string\n",
    "\n",
    "raw_text = request.urlopen(url).read().decode('utf8')\n",
    "\n",
    "print(raw_text[:75])\n",
    "\n",
    "type(raw_text), len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:75] \n",
    "# unicodedata.name('\\ufeff') # non-printable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tokenization**: break up strings into words and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffThe', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(list, 18)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "tokens = word_tokenize(raw_text[:100]+'2:00')\n",
    "\n",
    "print(tokens[:10])\n",
    "\n",
    "type(tokens), len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML\n",
    "(1) use a web browser to save a page as a local text file, then access the text file with normal text processing method\n",
    "\n",
    "(2) get python to do the work directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\">\\r\\n<html>\\r\\n<head>\\r\\n<title>BBC NEWS | Health | Blondes \\'to die out in 200 years\\'</title>\\r\\n<meta '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BBC News story: Blondes to die out in 200 years\n",
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = request.urlopen(url).read().decode('utf8')\n",
    "html[:200] \n",
    "# print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **BeautifulSoup**: a Python library to get text out of HTML\n",
    "    - http://www.crummy.com/software/BeautifulSoup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "BBC NEWS | Health | Blondes 'to die out in 200 years'\r\n",
      "<meta \n",
      "['BBC', 'NEWS', '|', 'Health', '|', 'Blondes', \"'to\", 'die', 'out', 'in']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "raw_text = BeautifulSoup(html[:200], 'html.parser').get_text()\n",
    "tokens = word_tokenize(raw_text)\n",
    "\n",
    "print(raw_text[:100])\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: BBC NEWS | Health | Blondes 'to die...>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize as nltk.Text, remove unwanted material\n",
    "text = nltk.Text(tokens[:10])\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing user input\n",
    "- Python built-in functions\n",
    "    - https://docs.python.org/3/library/functions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some text: Natural Language Processing\n"
     ]
    }
   ],
   "source": [
    "s = input(\"Enter some text: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./string_operations.png\" width=\"600\" align=\"center\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "318px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
