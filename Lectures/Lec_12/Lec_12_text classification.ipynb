{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "<b><font size=\"+3\">CS481-Lecture 11: Text Classification </font></b>\n",
    "<br>\n",
    "*[Illinois Institute of Technology](http://iit.edu)*\n",
    "\n",
    "</center>\n",
    "\n",
    "<br><br><br><br><br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification:\n",
    "\n",
    "The process of categorizing text into pre-defined groups/classes\n",
    "\n",
    "<img src=\"classification.png\" width=\"600\" align=\"left\">\n",
    "\n",
    "<br><br><br><br><br><br><br><br>\n",
    "Organize unstructured text to extract value and get insights into:\n",
    "    - social media messages\n",
    "    - emails\n",
    "    - online conversations (chat-bots)\n",
    "    - websites\n",
    "    \n",
    "    \n",
    "- **Applications** of automatic text classification:\n",
    "    - Sentiment Analysis: understand the view / attitute / feeling / emotion toward a situation or event. We do text classification to analyze if a given text is talking positively or negatively about a given subject (e.g. pos/neg movie review). \n",
    "\n",
    "    - Topic Labeling: identify the theme or topic in the text (e.g. analyze the topics of news articles: entertainment, business, politics).\n",
    "\n",
    "    - Spam Detection: detect whether an email is spam or not.\n",
    "\n",
    "\n",
    "\n",
    "- **Approaches**:\n",
    "    - manual\n",
    "        - human annotator read and label the text\n",
    "        - platform: AMT\n",
    "        - pros: high quality\n",
    "        - cons: time consuming and expensive  \n",
    "        \n",
    "    - automatic        \n",
    "        - rule-based\n",
    "            - pre-define a set of linguistic rules\n",
    "            - instruct the system to use semantically relevant elements of a text to identify relevant categories based on its content\n",
    "            - E.g., classify news article into sports and politics\n",
    "                - sports-related keywords: football, basketball, LeBron James\n",
    "                - politics-related keywords: government, Washington, Obama, Donald Trump, Hillary Clinton, etc.\n",
    "            - cons: difficult and expensive to maintain\n",
    "\n",
    "        - **machine learning-based**\n",
    "            - train a classifier based on pre-labeled training data\n",
    "            - apply the classifier to make predictions on new data\n",
    "            - pros: fast, effective, accurate\n",
    "            - cons: need pre-labeled training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary sentiment classification for IMDb movie reviews:\n",
    "\n",
    "- IMDb: Internet Movie Database, is an online database of information related to films, television programs, and so on.\n",
    "- Task: train a binary classification model to predict whether a movie review is positive or negative.\n",
    "\n",
    "<img src=\"IMDb_review.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "pd.set_option('display.max_colwidth', -1) # display the entire contents of each cell\n",
    "\n",
    "import seaborn as sns # visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and explore the data\n",
    "The data is available at this source, and you can learn more about how and why this dataset is created from this paper. <br>\n",
    "Data source: https://ai.stanford.edu/~amaas/data/sentiment/ <br>\n",
    "Paper: [Learning Word Vectors for Sentiment Analysis](https://ai.stanford.edu/~ang/papers/acl11-WordVectorsSentimentAnalysis.pdf) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. &lt;br /&gt;&lt;br /&gt;The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.&lt;br /&gt;&lt;br /&gt;This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.&lt;br /&gt;&lt;br /&gt;This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.&lt;br /&gt;&lt;br /&gt;3 out of 10 just for the well playing parents &amp; descent dialogs. As for the shots with Jake: just ignore them.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.&lt;br /&gt;&lt;br /&gt;The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.&lt;br /&gt;&lt;br /&gt;The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.&lt;br /&gt;&lt;br /&gt;We wish Mr. Mattei good luck and await anxiously for his next work.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.   \n",
       "1  A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "3  Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  positive  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((50000, 2), None)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we first download the data, and then use pandas dataframe to load the data from file\n",
    "df_data = pd.read_csv('IMDB Dataset.csv')\n",
    "df_data.shape, display(df_data.head())\n",
    "# we can see there are 50,000 reviews, each review is either positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('negative',\n",
       " 'Phil the Alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines.<br /><br />At first it was very odd and pretty funny but as the movie progressed I didn\\'t find the jokes or oddness funny anymore.<br /><br />Its a low budget film (thats never a problem in itself), there were some pretty interesting characters, but eventually I just lost interest.<br /><br />I imagine this film would appeal to a stoner who is currently partaking.<br /><br />For something similar but better try \"Brother from another planet\"')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is an example of negative review\n",
    "df_data.iloc[10].sentiment, df_data.iloc[10].review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then explore more about this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check empty cells\n",
    "df_data.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicate samples\n",
    "df_data = df_data.drop_duplicates(keep=\"first\")\n",
    "df_data.shape\n",
    "# compare with the original data 50,000, we removed about 500 duplicate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    24884\n",
       "negative    24698\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if pos and neg sentiments are balanced\n",
    "df_data.sentiment.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is equally distributed, which is great for building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets check the length of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    49582.000000\n",
       "mean      1310.568230\n",
       "std        990.762238\n",
       "min         32.000000\n",
       "25%        699.000000\n",
       "50%        971.000000\n",
       "75%       1592.000000\n",
       "max      13704.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['length'] = df_data['review'].apply(len) # number of characters\n",
    "df_data['length'].describe() # info()\n",
    "# the describe function shows the mean, std, min, max of length of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  length\n",
       "0  One of the other reviewers has mentioned that ...  positive    1761\n",
       "1  A wonderful little production. <br /><br />The...  positive     998\n",
       "2  I thought this was a wonderful way to spend ti...  positive     926\n",
       "3  Basically there's a family where a little boy ...  negative     748\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive    1317"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have a new column 'length' added to the dataframe\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of the length of positive and negative reviews\n",
    "# x: length of reviews; y: number of reviews fall into each interval\n",
    "df_data.hist(column='length', by='sentiment',bins=30, figsize=(12,4),rwidth=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above distribution, we can say that there is no clear difference between postive and negative reviews based on the length of the review.\n",
    "\n",
    "After the exploration, we now have a basic understanding of the dataset.\n",
    "Lets go ahead to clean the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing \n",
    "There are many approaches for text preprocessing, such as:\n",
    "- lowercasing\n",
    "- data cleaning \n",
    "    > remove special characters, emails, urls <br>\n",
    "    > remove stopwords <br>\n",
    "    > remove punctuations <br>\n",
    "        \n",
    "- normalization\n",
    "    > stemming \n",
    "        - chops off the ends of words to transform words into their root forms (e.g., connected->connect)\n",
    "        - PorterStemmer, SnowballStemmer\n",
    "    > lemmatization\n",
    "        - map a word to its root form (dictionary, rule-based) based on the context, POS, intended meaning\n",
    "        - WordNetLemmatizer\n",
    "        - transforming texts into a standard forms (abbreviations, misspellings, out-of-vocabulary words; e.g., gooood->good)\n",
    "    > De-contract\n",
    "        - expand the contracted words into normal words (I'm -> I am)\n",
    "\n",
    "The specific steps to apply depends on your task. <br>\n",
    "For our task of analyzing IMDb movie reviews data, we mainly focus on **data cleaning**, such as removing:\n",
    "\n",
    "> HTML tags <br>\n",
    "> special / non-alphabetic characters <br>\n",
    "> url <br>\n",
    "> emails <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an example of the review, we can see that ...\n",
    "df_data.review[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49582/49582 [00:25<00:00, 1946.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1761</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>998</td>\n",
       "      <td>A wonderful little production  The filming tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>926</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>748</td>\n",
       "      <td>Basically there is a family where a little boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1317</td>\n",
       "      <td>Petter Mattei is  Love in the Time of Money  i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  length  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive    1761   \n",
       "1  A wonderful little production. <br /><br />The...  positive     998   \n",
       "2  I thought this was a wonderful way to spend ti...  positive     926   \n",
       "3  Basically there's a family where a little boy ...  negative     748   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive    1317   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  One of the other reviewers has mentioned that ...  \n",
       "1  A wonderful little production  The filming tec...  \n",
       "2  I thought this was a wonderful way to spend ti...  \n",
       "3  Basically there is a family where a little boy...  \n",
       "4  Petter Mattei is  Love in the Time of Money  i...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def decontracted(phrase):\n",
    "    \"\"\"\n",
    "    We first define a function to expand the contracted phrase into normal words\n",
    "    \"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase) # prime \n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "def clean_text(df):\n",
    "    \"\"\"\n",
    "    Clean the review texts\n",
    "    \"\"\"\n",
    "    cleaned_review = []\n",
    "\n",
    "    for review_text in tqdm(df['review']):\n",
    "        \n",
    "        # expand the contracted words\n",
    "        review_text = decontracted(review_text)\n",
    "        \n",
    "        #remove html tags\n",
    "        review_text = BeautifulSoup(review_text, 'lxml').get_text().strip() # re.sub(r'<.*?>', '', text)\n",
    "        \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "        #remove url \n",
    "        review_text = re.sub(r'https?://\\S+|www\\.\\S+', '', review_text)\n",
    "        \n",
    "        #Removing punctutation, string.punctuation in python consists of !\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`\n",
    "        review_text = review_text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # ''.join([char for char in movie_text_data if char not in string.punctuation])\n",
    "        \n",
    "        # remove emails\n",
    "        review_text = re.sub(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", '', review_text)\n",
    "    \n",
    "        cleaned_review.append(review_text)\n",
    "\n",
    "    return cleaned_review\n",
    "\n",
    "df_data['cleaned_review'] = clean_text(df_data)\n",
    "# df_data['cleaned_review'] = df_data.apply(clean_text)\n",
    "# df_data = df_data.drop(columns=['review'])\n",
    "\n",
    "df_data.head()\n",
    "# After the cleaning process, we get the cleaned_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!! \n",
      "\n",
      "If you like original gut wrenching laughter you will like this movie  If you are young or old then you will love this movie  hell even my mom liked it Great Camp   \n"
     ]
    }
   ],
   "source": [
    "# example of a review before and after cleaning, we can see that the punctuations and html tags are removed.\n",
    "\n",
    "print(df_data['review'][9],'\\n')\n",
    "\n",
    "print(df_data['cleaned_review'][9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving forward, we convert the sentiments to binary labels, the corresponding label for postive sentiment is 1 and 0 for negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production  The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there is a family where a little boy...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei is  Love in the Time of Money  i...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_review sentiment  label\n",
       "0  One of the other reviewers has mentioned that ...  positive      1\n",
       "1  A wonderful little production  The filming tec...  positive      1\n",
       "2  I thought this was a wonderful way to spend ti...  positive      1\n",
       "3  Basically there is a family where a little boy...  negative      0\n",
       "4  Petter Mattei is  Love in the Time of Money  i...  positive      1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['label'] = df_data['sentiment'].map({'positive':1,'negative':0})\n",
    "df_data.head()[['cleaned_review','sentiment','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pipeline** for training a text classifier\n",
    "<img src=\"training.png\" width=\"800\" align=\"center\">\n",
    "\n",
    "## Tools and packages for ML:\n",
    "- **scikit-learn**: https://scikit-learn.org/stable/\n",
    "- a free software machine learning library for Python \n",
    "- algorithms for:\n",
    "    - feature engineering\n",
    "    - classification\n",
    "    - regression \n",
    "    - clustering\n",
    "    - evaluation metric (e.g., precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature engineering for text is the process of transforming a collection of texts into numerical feature vectors (vectorization) that the computers can understand.\n",
    "- Bag-of-words representation: documents are described by word occurrences while completely ignoring the relative position information of the words in the document\n",
    "- Vectorization: tokenization, counting and normalization\n",
    "\n",
    "\n",
    "**Feature engineering techniques**:\n",
    "- Units / levels\n",
    "    > words <br>\n",
    "    > ngram / phrases <br>\n",
    "    > sentences <br>\n",
    "    > POS tag <br>\n",
    "- doc:\n",
    "    > https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "- CountVectorizer \n",
    "    > represent document as a vector of word counts\n",
    "- TfidfVectorizer \n",
    "    > term-frequency * inverse document-frequency\n",
    "    > reduce very frequent terms (e.g., 'a', 'the', 'is')\n",
    "- Embedding \n",
    "    > represent words into high-dimensional vectors\n",
    "    > word2vec, BERT, GPT, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "- Convert a collection of text documents to a matrix of token counts\n",
    "- doc: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "         'This is the first document.',\n",
    "         'This document is the second document.',\n",
    "         'And this is the third one.',\n",
    "         'Is this the first document?',\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "ct_vectorizer = CountVectorizer()\n",
    "X = ct_vectorizer.fit_transform(corpus) # Learn the vocabulary dictionary and return document-term matrix\n",
    "print(X.toarray())\n",
    "# columns represent features\n",
    "# each row corresponds to a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 0]\n",
      " [0 2 0 0 1 0]\n",
      " [1 0 0 1 0 1]\n",
      " [0 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "ct_vectorizer = CountVectorizer(max_df = 0.8) # 4*0.8\n",
    "X = ct_vectorizer.fit_transform(corpus) # Learn the vocabulary dictionary and return document-term matrix\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<4x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(X))\n",
    "# print(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'one', 'second', 'third']\n"
     ]
    }
   ],
   "source": [
    "print(ct_vectorizer.get_feature_names()) # Array mapping from feature integer indices to feature name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': 2, 'document': 1, 'second': 4, 'and': 0, 'third': 5, 'one': 3}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_vectorizer.vocabulary_ # A mapping from terms to feature indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ngrams as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 0]\n",
      " [0 0 2 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0]\n",
      " [1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 0]\n",
      " [0 0 1 0 1 1 1 0 1 0 0 0 1 1 0 0 0 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "ct_vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "X2 = ct_vectorizer2.fit_transform(corpus)\n",
    "\n",
    "print(X2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'and this', 'document', 'document is', 'first', 'first document', 'is', 'is the', 'is this', 'one', 'second', 'second document', 'the', 'the first', 'the second', 'the third', 'third', 'third one', 'this', 'this document', 'this is', 'this the']\n"
     ]
    }
   ],
   "source": [
    "print(ct_vectorizer2.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Other important parameters:\n",
    "    > min_df: ignore terms that have a document frequency lower than the given threshold <br>\n",
    "    > max_df: ignore terms that have a document frequency lower than the given threshold(e.g., corpus-specific stop words) <br>\n",
    "    > lowercase <br>\n",
    "    > max_features <br>\n",
    "    > vocabulary <br>\n",
    "    > binary <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer\n",
    "- doc: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "- **tf-idf(t,d)** = tf(t,d)*idf(t)\n",
    "\n",
    "    - **tf(t,d)**: term-frequency, the number of times a term t occurs in a the document d\n",
    "\n",
    "    - **idf(t)**: inverse document frequency\n",
    "        - (norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "<img src=\"idf.png\" width=\"300\" align=\"center\">\n",
    "\n",
    "\n",
    "- Normalize the resulting tf-idf vectors by the **Euclidean norm**:\n",
    "    - Normalize each output row with unit norm\n",
    "        - https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-normalization\n",
    "        - **l2 norm**: sum of squares of vector elements is 1\n",
    "        - l1 norm: sum of absolute values of vector elements is 1\n",
    "        \n",
    "<img src=\"euclidean_norm.png\" width=\"500\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf(t,d), term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "ct_vectorizer = CountVectorizer()\n",
    "X = ct_vectorizer.fit_transform(corpus)\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- idf(t): inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 2, 4, 1, 1, 4, 1, 4]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate df(t)\n",
    "vectorizer = CountVectorizer(binary=True) # binary representation\n",
    "X_bi = vectorizer.fit_transform(corpus) \n",
    "df_t_list = X_bi.sum(axis=0).tolist()[0] # document frequency for each feature\n",
    "df_t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.916290731874155, 1.2231435513142097, 1.5108256237659907, 1.0, 1.916290731874155, 1.916290731874155, 1.0, 1.916290731874155, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# calculate inverse document frequenct\n",
    "\n",
    "idf_list = []\n",
    "n = 4\n",
    "for df_t in df_t_list:\n",
    "    idf_list.append(np.log((1+n)/(1+df_t))+1)\n",
    "\n",
    "print(idf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.2231435513142097, 1.5108256237659907, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# calculate tf*idf\n",
    "tf_list = X.toarray()[0]\n",
    "tf_idf_list = []\n",
    "for tf,idf in zip(tf_list, idf_list):\n",
    "    tf_idf_list.append(tf*idf)\n",
    "\n",
    "print(tf_idf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.46979138557992045, 0.5802858236844359, 0.38408524091481483, 0.0, 0.0, 0.38408524091481483, 0.0, 0.38408524091481483]\n"
     ]
    }
   ],
   "source": [
    "# normalize each output row (l2 norm)\n",
    "square_sum = 0\n",
    "for tf_idf in tf_idf_list:\n",
    "    square_sum += tf_idf**2\n",
    "    \n",
    "tf_idf_norm = []\n",
    "for tf_idf in tf_idf_list:\n",
    "    tf_idf_norm.append(tf_idf/np.sqrt(square_sum))\n",
    "\n",
    "print(tf_idf_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use TfidfVectorizer to integrate all the process into one line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 9)\n",
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      "  0.28108867 0.         0.28108867]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering for this task (sentiment classification for IMDb movie reviews) \n",
    "- use the **scikit-learn** implementation of [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to convert the movie reviews into a 2-d matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape :  (49582, 47192)\n",
      "y.shape :  (49582,)\n"
     ]
    }
   ],
   "source": [
    "# print(stopwords.words('english'))\n",
    "#Exluding NO, NOR, NOT from the stop words as they play keyrole\n",
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "\n",
    "\n",
    "# CountVectorizer: lowercase the text, use a self-defined stopwords list to remove stopwords\n",
    "# Will talk about how to tune these parameters later.\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words=stopwords, max_df=0.9, min_df=3, ngram_range=(1,1))\n",
    "\n",
    "# convert the cleaned reviews to vectors\n",
    "X = vectorizer.fit_transform(df_data.cleaned_review)\n",
    "y = df_data.label.values\n",
    "\n",
    "print(\"X.shape : \",X.shape)\n",
    "print(\"y.shape : \",y.shape)\n",
    "\n",
    "# y is the array of sentiment labels\n",
    "\n",
    "# X is the 2-d matrix of vector representation of the cleaned reviews\n",
    "# each row corresponds to each document and each column corresponds to each feature\n",
    "# accoring to the shape of X, we can tell the number of samples, the number of features (size of vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split\n",
    "- Shuffle the data \n",
    "- Split the data into training and testing by 80:20 ratio\n",
    "- Assign a random state for reproducible output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 5)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49989</th>\n",
       "      <td>I got this one a few weeks ago and love it! It...</td>\n",
       "      <td>positive</td>\n",
       "      <td>967</td>\n",
       "      <td>I got this one a few weeks ago and love it  It...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49990</th>\n",
       "      <td>Lame, lame, lame!!! A 90-minute cringe-fest th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>799</td>\n",
       "      <td>Lame  lame  lame    A    minute cringe fest th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49992</th>\n",
       "      <td>John Garfield plays a Marine who is blinded by...</td>\n",
       "      <td>positive</td>\n",
       "      <td>968</td>\n",
       "      <td>John Garfield plays a Marine who is blinded by...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49993</th>\n",
       "      <td>Robert Colomb has two full-time jobs. He's kno...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2717</td>\n",
       "      <td>Robert Colomb has two full time jobs  He is kn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49994</th>\n",
       "      <td>This is your typical junk comedy.&lt;br /&gt;&lt;br /&gt;T...</td>\n",
       "      <td>negative</td>\n",
       "      <td>759</td>\n",
       "      <td>This is your typical junk comedy There are alm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1008</td>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>642</td>\n",
       "      <td>Bad plot  bad dialogue  bad acting  idiotic di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1280</td>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1234</td>\n",
       "      <td>I am going to have to disagree with the previo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>678</td>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  length  \\\n",
       "49989  I got this one a few weeks ago and love it! It...  positive     967   \n",
       "49990  Lame, lame, lame!!! A 90-minute cringe-fest th...  negative     799   \n",
       "49992  John Garfield plays a Marine who is blinded by...  positive     968   \n",
       "49993  Robert Colomb has two full-time jobs. He's kno...  negative    2717   \n",
       "49994  This is your typical junk comedy.<br /><br />T...  negative     759   \n",
       "49995  I thought this movie did a down right good job...  positive    1008   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative     642   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative    1280   \n",
       "49998  I'm going to have to disagree with the previou...  negative    1234   \n",
       "49999  No one expects the Star Trek movies to be high...  negative     678   \n",
       "\n",
       "                                          cleaned_review  label  \n",
       "49989  I got this one a few weeks ago and love it  It...      1  \n",
       "49990  Lame  lame  lame    A    minute cringe fest th...      0  \n",
       "49992  John Garfield plays a Marine who is blinded by...      1  \n",
       "49993  Robert Colomb has two full time jobs  He is kn...      0  \n",
       "49994  This is your typical junk comedy There are alm...      0  \n",
       "49995  I thought this movie did a down right good job...      1  \n",
       "49996  Bad plot  bad dialogue  bad acting  idiotic di...      0  \n",
       "49997  I am a Catholic taught in parochial elementary...      0  \n",
       "49998  I am going to have to disagree with the previo...      0  \n",
       "49999  No one expects the Star Trek movies to be high...      0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index is not continuous because some rows are deleted during data pre-processing\n",
    "df_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49577</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1008</td>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49578</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>642</td>\n",
       "      <td>Bad plot  bad dialogue  bad acting  idiotic di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49579</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1280</td>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49580</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1234</td>\n",
       "      <td>I am going to have to disagree with the previo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49581</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>678</td>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  length  \\\n",
       "49577  I thought this movie did a down right good job...  positive    1008   \n",
       "49578  Bad plot, bad dialogue, bad acting, idiotic di...  negative     642   \n",
       "49579  I am a Catholic taught in parochial elementary...  negative    1280   \n",
       "49580  I'm going to have to disagree with the previou...  negative    1234   \n",
       "49581  No one expects the Star Trek movies to be high...  negative     678   \n",
       "\n",
       "                                          cleaned_review  label  \n",
       "49577  I thought this movie did a down right good job...      1  \n",
       "49578  Bad plot  bad dialogue  bad acting  idiotic di...      0  \n",
       "49579  I am a Catholic taught in parochial elementary...      0  \n",
       "49580  I am going to have to disagree with the previo...      0  \n",
       "49581  No one expects the Star Trek movies to be high...      0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the index to make it continuous \n",
    "# make the index for X (vector representation) consistent with the index for the documents\n",
    "# make the vector representation of the data align with the raw text\n",
    "df_data_reidx = df_data.reset_index(drop=True)\n",
    "df_data_reidx.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:39665\n",
      "Number of testing examples:9917\n"
     ]
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(np.arange(df_data_reidx.shape[0]), test_size=0.2, shuffle=True, random_state=42)\n",
    "len(train_idx), len(test_idx)\n",
    "print(\"Number of training examples:{}\".format(len(train_idx)))\n",
    "print(\"Number of testing examples:{}\".format(len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: X_train : (39665, 47192), y_train : (39665,)\n",
      "Testing data: X_test : (9917, 47192), y_test : (9917,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[train_idx]\n",
    "y_train = y[train_idx]\n",
    "\n",
    "X_test = X[test_idx]\n",
    "y_test = y[test_idx]\n",
    "\n",
    "print(\"Training data: X_train : {}, y_train : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Testing data: X_test : {}, y_test : {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "After we do text preprocessing, feature engineering, and train test split, the next step is model training, we need to decide which model to use. For example, there are:\n",
    "\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Decision Tree\n",
    "- K-Nearest Neighbors\n",
    "- Support Vector Machines\n",
    "- (Deep) Neural Networks\n",
    "- ... many many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"training_prediction.png\" width=\"800\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "In this task, we will use **Logistic regression**, which is one of the most popular and interpretable machine learning algorithm for binary classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression**: linear combination of independent variables,\n",
    "$$\n",
    "    t = \\sum_{i} {\\beta_i*x_i}\n",
    "$$\n",
    "\n",
    "**Logistic Regression**: regression with output constrained between 0 and 1 with a **sigmoid logistic function**, as we see here, combine the linear regression with a logistic function, we get the logistic regression function:\n",
    "  \n",
    "$$ \n",
    "    \\hat{y} = \\frac{1}{1 + \\exp^{(- t)}}  = \\frac{1}{1 + \\exp^{(-\\sum_i\\beta_i x_i)}} \n",
    "$$\n",
    "\n",
    "- $x_i$ is value of feature $i$ in an instance (count of a word)<br>\n",
    "- $\\beta_i$ is the real-valued model parameter associated with feature $i$ <br>\n",
    "  - E.g., high $\\beta_i$ means feature $i$ is predictive of positive class ($y=1$) <br>\n",
    "- $\\hat{y}$ is the probability of being positive, $y$ is the actual label <br>\n",
    "    - If $\\hat{y} > .5$, classify as positive, $y = 1$ <br>\n",
    "\n",
    "\n",
    "<img src=\"Logistic_curve.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a logistic regression classifier on the training data use default settings\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "# make prediction on testing data\n",
    "y_pred_test = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the model prediction\n",
    "- Check the reviews that the model fails to predict its true sentiment\n",
    "- Check the top features that are predictive of positive sentiments and negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29035</th>\n",
       "      <td>\"Soul Plane\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. &lt;br /&gt;&lt;br /&gt;The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \"Adult\" section. OK?&lt;br /&gt;&lt;br /&gt;I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.&lt;br /&gt;&lt;br /&gt;2/10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43282</th>\n",
       "      <td>Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \"Nick\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38461</th>\n",
       "      <td>\"National Treasure\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy cliché that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another  attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.&lt;br /&gt;&lt;br /&gt;The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble  if confusing. He's set on protecting the treasure. For who and when?",
       "your guess is as good as mine.&lt;br /&gt;&lt;br /&gt;But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah  brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut  at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \"is that the Hope Diamond?\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \"National Treasure\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.&lt;br /&gt;&lt;br /&gt;The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted  just the thick-headed.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        review  \\\n",
       "29035  \"Soul Plane\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \"Adult\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "43282  Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \"Nick\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "38461  \"National Treasure\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy cliché that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another  attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble  if confusing. He's set on protecting the treasure. For who and when?\n",
       "your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah  brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut  at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \"is that the Hope Diamond?\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \"National Treasure\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted  just the thick-headed.   \n",
       "\n",
       "       label  pred_label  \n",
       "29035  0      0           \n",
       "43282  1      1           \n",
       "38461  0      0           "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_data_reidx.iloc[test_idx]\n",
    "df_test['pred_label'] = y_pred_test\n",
    "df_test.head(3)[['review','label','pred_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47410</th>\n",
       "      <td>His significant charisma and commanding presence are about all that keep this afloat, but Fred Williamson has done far better urban action films including many of his later, vid-released fare. The big studios' Williamson films of the early-to-mid 70's rarely had the punch of their mid-level counterparts, and this is a prime example. Clumsy action, little violence, and the PG rating is nowhere near questionable. Worth a look for Hammer completists in any case.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30610</th>\n",
       "      <td>I preface by stating I am a big fan of JJL and NOT one of Patrick. Therefore I watched this to see her performance and of course, it was excellent. I do not feel the director was adequate for the film as several very bad choices were made re: shot angles, blocking, etc. If the director was trying to give it a \"realistic\" feel, they failed and lost some good performances because of it. Nearly always felt that the camera was way too static, too far from intense facial reactions -- and so many times when the action depended on the intimacy of lead characters, the dialog was slow and plodding. This easily could have been resolved by cutaways or changes of camera angle. But the impression I got was that the budget was too small and only one camera was used! I also got the impression that perhaps scenes were shot multiple times and the energy coming from the actors was... used up.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39877</th>\n",
       "      <td>A horror movie is being shot and things aren't going well. It's about a masked killer. The director tells off the killer in front of the cast and crew. He goes crazy and kills two people. He's killed himself and the film is never finished. Twelve years later a bunch of film students decide to try and finish it--but there's a curse. People who try and finish it are killed themselves. The students ignore that. Guess what happens next?&lt;br /&gt;&lt;br /&gt;The plot is old hat but this isn't bad...for what it is (a low budget slasher film). It's well-made with a young and fairly talented young cast. No one is great but no one is terrible either. It also avoids the obligatory (and needless) female nude scenes. It moves quickly, the gore is nice and bloody and the script doesn't insult your intelligence. Also Molly Ringwald is in this having the time of her life playing a bitchy faded actress.&lt;br /&gt;&lt;br /&gt;No great shakes but not bad at all. I give it a 7.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42613</th>\n",
       "      <td>There is only one racist joke in this Daffy Duck short, which is basically, when Daffy rides Black Beauty, it is a black woman. I can understand partly why this joke was included, as at the time few people did not know how rude it was to be racist and it wasn't even illegal to discriminate black people yet.&lt;br /&gt;&lt;br /&gt;Aside from this point, \"A Coy Decoy\" is basically a fun, interesting short where Daffy meets characters in books and does things in books. I liked this short quite a lot (despite the other reviewers on here). The way Daffy is so in love with the clockwork duck is vaguely disturbing, yet highly amusing at the same time. Porky is a nice edition to the episode, though it was not vital for him to be there. The wolf is an example of how people thought of wolves in those days as well, blood-thirsty, terrible animals, which of course they never really have been (unless they are very hungry). I also liked the style of animation used - and the theme of the episode.&lt;br /&gt;&lt;br /&gt;For people who are totally into Daffy Duck and for people who do not mind the occasional racist joke in cartoons, enjoy \"A Coy Decoy\"!&lt;br /&gt;&lt;br /&gt;Available on YouTube.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42860</th>\n",
       "      <td>I've been a classic horror fan my entire life. Many nights stretched until the early hours of the morning watching the Universal films on \"Horror Incorporated\" and \"Creature Feature Night\". Sadly, I viewed this film in the early evening and yet it still almost put me to sleep.&lt;br /&gt;&lt;br /&gt;I don't think I've ever seen a \"horror\" picture where everything was so matter of fact. Dr. Edelmann doesn't seem to believe in the supernatural, yet before long he's medically treating Dracula and watching Larry Talbot change into the Wolfman while hardly blinking an eye. He and Talbot discover the Frankenstein monster like it's an everyday occurrence. Edelmann is all fired up to bring the monster back to life, but after Talbot, Miliza and Nina protest he's like \"Aww, you're right. No big deal\". After realizing Dracula's treachery, he opens the Count's coffin to sunlight and POOF!, he's gone, just like that.&lt;br /&gt;&lt;br /&gt;The only person who didn't appear to just be phoning in her lines was Jane Adams as Nina. Her reward is getting bounced off the hump in her back into a pit by the Frankenstein Monster at the end of the film...and no one even tries to rescue her! She, Dr. Edelmann and the Monster all perish, while Talbot and Miliza casually leave the castle.&lt;br /&gt;&lt;br /&gt;Definitely the low point for Universal during it's classic horror years.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                review  \\\n",
       "47410  His significant charisma and commanding presence are about all that keep this afloat, but Fred Williamson has done far better urban action films including many of his later, vid-released fare. The big studios' Williamson films of the early-to-mid 70's rarely had the punch of their mid-level counterparts, and this is a prime example. Clumsy action, little violence, and the PG rating is nowhere near questionable. Worth a look for Hammer completists in any case.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "30610  I preface by stating I am a big fan of JJL and NOT one of Patrick. Therefore I watched this to see her performance and of course, it was excellent. I do not feel the director was adequate for the film as several very bad choices were made re: shot angles, blocking, etc. If the director was trying to give it a \"realistic\" feel, they failed and lost some good performances because of it. Nearly always felt that the camera was way too static, too far from intense facial reactions -- and so many times when the action depended on the intimacy of lead characters, the dialog was slow and plodding. This easily could have been resolved by cutaways or changes of camera angle. But the impression I got was that the budget was too small and only one camera was used! I also got the impression that perhaps scenes were shot multiple times and the energy coming from the actors was... used up.                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "39877  A horror movie is being shot and things aren't going well. It's about a masked killer. The director tells off the killer in front of the cast and crew. He goes crazy and kills two people. He's killed himself and the film is never finished. Twelve years later a bunch of film students decide to try and finish it--but there's a curse. People who try and finish it are killed themselves. The students ignore that. Guess what happens next?<br /><br />The plot is old hat but this isn't bad...for what it is (a low budget slasher film). It's well-made with a young and fairly talented young cast. No one is great but no one is terrible either. It also avoids the obligatory (and needless) female nude scenes. It moves quickly, the gore is nice and bloody and the script doesn't insult your intelligence. Also Molly Ringwald is in this having the time of her life playing a bitchy faded actress.<br /><br />No great shakes but not bad at all. I give it a 7.                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "42613  There is only one racist joke in this Daffy Duck short, which is basically, when Daffy rides Black Beauty, it is a black woman. I can understand partly why this joke was included, as at the time few people did not know how rude it was to be racist and it wasn't even illegal to discriminate black people yet.<br /><br />Aside from this point, \"A Coy Decoy\" is basically a fun, interesting short where Daffy meets characters in books and does things in books. I liked this short quite a lot (despite the other reviewers on here). The way Daffy is so in love with the clockwork duck is vaguely disturbing, yet highly amusing at the same time. Porky is a nice edition to the episode, though it was not vital for him to be there. The wolf is an example of how people thought of wolves in those days as well, blood-thirsty, terrible animals, which of course they never really have been (unless they are very hungry). I also liked the style of animation used - and the theme of the episode.<br /><br />For people who are totally into Daffy Duck and for people who do not mind the occasional racist joke in cartoons, enjoy \"A Coy Decoy\"!<br /><br />Available on YouTube.                                                                                                                                                                                       \n",
       "42860  I've been a classic horror fan my entire life. Many nights stretched until the early hours of the morning watching the Universal films on \"Horror Incorporated\" and \"Creature Feature Night\". Sadly, I viewed this film in the early evening and yet it still almost put me to sleep.<br /><br />I don't think I've ever seen a \"horror\" picture where everything was so matter of fact. Dr. Edelmann doesn't seem to believe in the supernatural, yet before long he's medically treating Dracula and watching Larry Talbot change into the Wolfman while hardly blinking an eye. He and Talbot discover the Frankenstein monster like it's an everyday occurrence. Edelmann is all fired up to bring the monster back to life, but after Talbot, Miliza and Nina protest he's like \"Aww, you're right. No big deal\". After realizing Dracula's treachery, he opens the Count's coffin to sunlight and POOF!, he's gone, just like that.<br /><br />The only person who didn't appear to just be phoning in her lines was Jane Adams as Nina. Her reward is getting bounced off the hump in her back into a pit by the Frankenstein Monster at the end of the film...and no one even tries to rescue her! She, Dr. Edelmann and the Monster all perish, while Talbot and Miliza casually leave the castle.<br /><br />Definitely the low point for Universal during it's classic horror years.   \n",
       "\n",
       "       label  pred_label  \n",
       "47410  0      1           \n",
       "30610  0      1           \n",
       "39877  1      0           \n",
       "42613  1      0           \n",
       "42860  0      1           "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['label'] != df_test['pred_label']].head()[['review','label','pred_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top-10 words that are predictive of positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('refreshing', 1.865),\n",
       " ('disappoint', 1.85),\n",
       " ('hooked', 1.716),\n",
       " ('superb', 1.444),\n",
       " ('entertains', 1.409),\n",
       " ('squirrel', 1.409),\n",
       " ('adr', 1.382),\n",
       " ('ringwald', 1.358),\n",
       " ('perfect', 1.343),\n",
       " ('excellent', 1.336)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_to_coef = {word: float(\"%.3f\" % coef) for word, coef in zip(vectorizer.get_feature_names(), lr_clf.coef_[0])}\n",
    "\n",
    "print(\"Top positive features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# words like \"refreshing, hooked, superb\" are reliable evidence of indicating positive sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top-10 words that are predictive of negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top negative features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('waste', -2.173),\n",
       " ('worst', -2.146),\n",
       " ('uninteresting', -1.95),\n",
       " ('disappointment', -1.824),\n",
       " ('mildly', -1.733),\n",
       " ('forgettable', -1.714),\n",
       " ('stinker', -1.627),\n",
       " ('awful', -1.577),\n",
       " ('dreadful', -1.554),\n",
       " ('fails', -1.548)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most of the words are reliable evidence of indicating negative sentiments\n",
    "print(\"Top negative features:\")\n",
    "sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "- train test split\n",
    "- k-fold cross-validation \n",
    "> train on k-1 folds, test on 1 fold, repeat k times <br>\n",
    "> each instance appears only once in test set <br>\n",
    "\n",
    "- Scoring metrics\n",
    "> assign different scoring metrics to check the model performance from different aspects <br>\n",
    "> https://scikit-learn.org/stable/modules/model_evaluation.html <br>\n",
    "> precision, recall, f1 <br>\n",
    "> accuracy <br>\n",
    "> roc_auc <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      4939\n",
      "           1       0.88      0.89      0.88      4978\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      9917\n",
      "   macro avg       0.88      0.88      0.88      9917\n",
      "weighted avg       0.88      0.88      0.88      9917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))\n",
    "# micro average (averaging the total true positives, false negatives and false positives globally, true pos of one class / (all true pos + all false pos))\n",
    "# macro average (averaging the unweighted mean per label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the evaluation scores we can say that the model is working pretty decent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88352778 0.87779758 0.87770498 0.87245805 0.88951161]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lr_clf, X, y, cv=5, scoring='precision')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
